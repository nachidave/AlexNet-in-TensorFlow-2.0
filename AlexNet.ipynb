{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.image as img\n",
    "from os import listdir\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiating and Compiling the Model (AlexNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(96,(11,11),strides=4,activation='relu',input_shape=(227,227,3)),\n",
    "    tf.keras.layers.MaxPooling2D((3,3),strides=2),\n",
    "    tf.keras.layers.Conv2D(256,(5,5),padding='same',activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((3,3),strides=2),\n",
    "    tf.keras.layers.Conv2D(384,(3,3),padding='same',activation='relu'),\n",
    "    tf.keras.layers.Conv2D(256,(3,3),padding='same',activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((3,3),strides=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(9216,activation='relu'),\n",
    "    tf.keras.layers.Dense(4096,activation='relu'),\n",
    "    tf.keras.layers.Dense(4096,activation='relu'),\n",
    "    tf.keras.layers.Dense(3,activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data\n",
    "dog_img=[]\n",
    "cat_img=[]\n",
    "dog_add='address'\n",
    "cat_add='address'\n",
    "add=[dog_add,cat_add]\n",
    "for i in add:\n",
    "    for filename in listdir(i):\n",
    "        image_data=img.imread(i + '/' + filename)\n",
    "        if i==dog_add:\n",
    "            dog_img.append(image_data)\n",
    "        else:\n",
    "            cat_img.append(image_data)\n",
    "img_labels=[0]*len(dog_img)+[1]*len(cat_img)\n",
    "all_img=dog_img + cat_img\n",
    "labels={0:\"Dog\" , 1:\"Cat\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "all_img_1=[]\n",
    "size=(0,0,227,227)\n",
    "for f in range(len(all_img)):\n",
    "    a=Image.fromarray(all_img[f])\n",
    "    b=a.crop(size)\n",
    "    all_img_1.append(b)\n",
    "\n",
    "import numpy as np\n",
    "data=[]\n",
    "for i in range(len(all_img_1)):\n",
    "    d=np.array(all_img_1[i])\n",
    "    data.append(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the images into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(all_img[:4000],img_labels[:4000],test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting train and test set into numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "len(X_train)\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test=np.array(X_test)\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latest model will be saved after each epoch when training\n",
    "\n",
    "import os\n",
    "\n",
    "model_path='address where model is to be saved'\n",
    "\n",
    "model_dir=os.path.dirname(model_path)\n",
    "\n",
    "model_callback=tf.keras.callbacks.ModelCheckpoint(model_path,save_weights_only=True,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitting=model.fit(X_train,y_train,epochs=200,validation_split=0.25,batch_size=100,steps_per_epoch=15,shuffle=True,use_multiprocessing=True,callbacks=[model_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading pre-trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,y_test,batch_size=100,use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting training and validation error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "epochs = 50\n",
    "learning_rate = 0.0005\n",
    "decay_rate = learning_rate / epochs\n",
    "opt = Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=decay_rate, amsgrad=False)\n",
    "model.compile(optimizer=opt,loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "#model.compile(loss='sparse_categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "val_loss = new_fitting.history['val_loss']\n",
    "loss = new_fitting.history['loss']\n",
    "epochs = range(len(loss))\n",
    "plt.plot(epochs,loss)\n",
    "plt.title(\"Training Loss\")\n",
    "plt.show()\n",
    "plt.plot(epochs,val_loss,'r')\n",
    "plt.title(\"Validation Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
